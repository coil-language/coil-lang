def Tokenizer(@entries) end

def pass() end
def newline() end

def Tokenizer:prototype.invoke(str)
  let tokens = []
  let index = 0
  def rest_of_string() = str:slice(index)

  def scan(pattern)
    let result = rest_of_string().:match(pattern)
    if result.nil?() or result:index != 0
      return false
    else
      index = index + result.0.:length
      return result.0
    end
  end

  let line = 1
  let col = 1
  while rest_of_string() != ""
    let found = false
    for [pattern type] of this:entries
      if let value = scan(pattern)
        if type == newline
          line = line + 1
          col = 1
        else if type != pass
          tokens:push({
            type: type,
            value: value,
            line: line,
            col: col
          })
          col = col + value.len()
        else
          col = col + value.len()
        end
        found = true
        break
      end
    end
    if !found
      panic!("No token matched.")
    end
  end

  return tokens
end

let tokenize = Tokenizer{
  /^\n/ => newline
  /^\s+/ => pass
  /^\#.*/ => pass
  /^\-\-.*/ => pass
  /^\,/ => pass
  /^\;/ => pass
  /^if\s/ => :if
  /^else\s/ => :else
  /^return\s/ => :return
  /^import\s/ => :import
  /^export\s/ => :export
  /^default\s/ => :default
  /^from\s/ => :from
  /^let\s/ => :let
  /^protocol\s/ => :protocol
  /^for\s/ => :for
  /^try\s/ => :try
  /^catch\s/ => :catch
  /^finally\s/ => :finally
  /^instanceof\s/ => :instanceof
  /^end\b/ => :end
  /^while\s/ => :while
  /^loop\s/ => :loop
  /^and\s/ => :and
  /^or\s/ => :or
  /^continue\s/ => :continue
  /^break\s/ => :break
  /^of\s/ => :of
  /^yield\b/ => :yield
  /^async\s/ => :async
  /^await\s/ => :await
  /^\=\>/ => :arrow
  /^\@/ => :at
  /^\=\=/ => :double_eq
  /^\!\=/ => :not_eq
  /^\!/ => :bang
  /^\=/ => :eq
  /^def\b/ => :def
  /^\{/ => :open_b
  /^\}/ => :close_b
  /^\(/ => :open_p
  /^\)/ => :close_p
  /^\|/ => :pipe_bar
  /^[\-\+]?(\d+\.)?\d+n/ => :bigint
  /^[\-\+]?(\d+\.)?\d+/ => :num
  /^\.\.\./ => :dot_dot_dot
  /^\.\./ => :dot_dot
  /^\./ => :dot
  /^\/.*\/[a-z]?/ => :regex_lit
  /^\>\=/ => :gt_eq
  /^\<\=/ => :lt_eq
  /^\>/ => :gt
  /^\</ => :lt
  /^\+/ => :plus
  /^\%/ => :mod
  /^\-/ => :minus
  /^\*\*/ => :pow
  /^\*/ => :times
  /^\// => :div
  /^\[/ => :open_sq
  /^\]/ => :close_sq
  /^\"([^\\\"]|\\.)*\"/s => :string_lit
  /^[a-zA-Z_\?\!\$0-9]+/ => :id
  /^\:[a-zA-Z_\?\!\$0-9]+/ => :keyword
  /^\:/ => :colon
}

export default tokenize
