import { ParseError } from "./parse_error.js"

fn str(...args) = args.map(|arg| arg:toString()).join("")

fn CollectionView(@collection, @idx) end

fn CollectionView:prototype.(Collection:len) =
  this:collection.len() - this:idx

fn CollectionView:prototype.(Collection:empty?) =
  this.len() == 0

fn CollectionView:prototype.(Collection:at)(idx) =
  this:collection.at(this:idx + idx)

fn CollectionView:prototype.(OrderedSequence:first) =
  this:collection.at(this:idx)

fn CollectionView:prototype.(OrderedSequence:last) =
  this:collection.last()

fn CollectionView:prototype:skip(n) =
  CollectionView[this:collection, this:idx + n]

fn* CollectionView:prototype.(Symbol:iterator)
  for i of this:idx..this:collection.len()
    yield this:collection.i
  end
end

fn Lexer(@entries) end

fn pass() end
fn newline() end

fn Lexer:prototype.invoke(str)
  let tokens = []
  let index = 0
  fn rest_of_string() = str:slice(index)

  fn scan(pattern)
    let result = rest_of_string().:match(pattern)
    if result.nil?() or result:index != 0
      return false
    else
      index = index + result.0.:length
      return result.0
    end
  end

  let line = 1
  let col = 1
  while rest_of_string() != ""
    let found = false
    for [pattern type] of this:entries
      if let value = scan(pattern)
        if type == newline
          line = line + 1
          col = 1
        else if type != pass
          tokens:push({type: type, value: value, line: line, col: col})
          col = col + value.len()
        else
          col = col + value.len()
        end
        found = true
        break
      end
    end
    if !found
      raise!(Error["No token matched."])
    end
  end

  return tokens
end

let lexer = Lexer{
  /^\n/ => newline
  /^\s+/ => pass
  /^\#.*/ => pass
  /^\,/ => pass
  /^\;/ => pass
  /^if\s/ => :if
  /^else\s/ => :else
  /^return\s/ => :return
  /^import\s/ => :import
  /^export\s/ => :export
  /^default\s/ => :default
  /^from\s/ => :from
  /^let\s/ => :let
  /^protocol\s/ => :protocol
  /^for\s/ => :for
  /^try\s/ => :try
  /^catch\s/ => :catch
  /^finally\s/ => :finally
  /^end\s/ => :end
  /^while\s/ => :while
  /^loop\s/ => :loop
  /^and\s/ => :and
  /^or\s/ => :or
  /^continue\s/ => :continue
  /^break\s/ => :break
  /^of\s/ => :of
  /^yield\s/ => :yield
  /^async\s/ => :async
  /^await\s/ => :await
  /^\=\>/ => :arrow
  /^\@/ => :at
  /^\=\=/ => :double_eq
  /^\!\=/ => :not_eq
  /^\!/ => :bang
  /^\=/ => :eq
  /^fn\b/ => :fn
  /^\{/ => :open_b
  /^\}/ => :close_b
  /^\(/ => :open_p
  /^\)/ => :close_p
  /^\|/ => :pipe_bar
  /^[\-\+]?(\d+\.)?\d+n/ => :bigint
  /^[\-\+]?(\d+\.)?\d+/ => :num
  /^\.\.\./ => :dot_dot_dot
  /^\.\./ => :dot_dot
  /^\./ => :dot
  /^\/.*\/[a-z]?/ => :regex_lit
  /^\>\=/ => :gt_eq
  /^\<\=/ => :lt_eq
  /^\>/ => :gt
  /^\</ => :lt
  /^\+/ => :plus
  /^\%/ => :mod
  /^\-/ => :minus
  /^\*\*/ => :pow
  /^\*/ => :times
  /^\// => :div
  /^\[/ => :open_sq
  /^\]/ => :close_sq
  /^\"([^\\\"]|\\.)*\"/s => :string_lit
  /^[a-zA-Z_\?\!\$0-9]+/ => :id
  /^\:[a-zA-Z_\?\!\$0-9]+/ => :keyword
  /^\:/ => :colon
}

fn expect_token!(tokens, kw)
  if tokens.first().at(:type) != kw
    raise!(ParseError[kw, tokens.first()])
  else
    return tokens
  end
end

fn verify_exists!(expr, parser)
  if expr.nil?()
    raise!(Error["Parser Failed - Expected " + parser])
  else
    return expr
  end
end

#  PARSER MACHINE IMPL

protocol parse

fn line_and_col({line, col}) = {line: line, col: col}

fn Init(@expr) end
fn Init:prototype.parse([_expr tokens]) = 
  [{...this:expr, pos: line_and_col(tokens.first())} tokens]

fn One(@kw, @as) end
fn One:prototype.parse([expr tokens])
  let {value, type} = expect_token!(tokens this:kw).first()
  return [{...expr, this:as => value} tokens:skip(1)]
end

protocol can_parse?

fn Keyword:prototype.can_parse?([{type}]) = this == type

fn Set:prototype.can_parse?(tokens) =
  this.any?(|cond| cond.can_parse?(tokens))

fn _.can_parse?([]) = true

fn Array:prototype.can_parse?(tokens)
  if this.len() > tokens.len()
    return false
  else
    return this.zip(tokens).all?(|[pattern token]| pattern.can_parse?([token]))
  end
end

fn Optional(@parse_cond, @parse_fn, @as) end
fn Optional:prototype.parse([expr tokens])
  if tokens.empty?()
    return [expr tokens]
  else if this:parse_cond.can_parse?(tokens)
    return Then[this.:parse_fn, this.:as].parse([expr tokens])
  else
    return [expr tokens]
  end
end

fn Function:prototype.parse([_expr tokens]) = this(tokens)

fn Chomp(...@kws) end
fn Chomp:prototype.parse([expr tokens])
  let i = 0
  for kw of this:kws
    expect_token!(tokens:skip(i), kw)
    i = i + 1
  end
  return [expr, tokens:skip(i)]
end

fn Then(@parser, @kw) end
fn Then:prototype.parse([expr tokens])
  if let [new_expr new_tokens] = this:parser(tokens)
    if this:kw
      return [{...expr, this:kw => new_expr} new_tokens]
    else
      return [new_expr new_tokens]
    end
  else
    return [expr tokens]
  end
end

fn FMap(@f) end
fn FMap:prototype.parse([expr tokens]) = [this:f(expr) tokens]

fn Until(@end_kw, @parser, @kw) end
fn Until:prototype.parse([expr tokens])
  let exprs = []
  while tokens.first().at(:type) != this:end_kw
    let [expr new_tokens] = verify_exists!(this:parser(tokens) this)
    exprs.:push(expr)
    tokens = new_tokens
  end
  if this:kw
    return [{...expr this:kw => exprs} tokens]
  else
    return [exprs, tokens]
  end
end

fn UntilEither(@set, @parser, @kw) end
fn UntilEither:prototype.parse([expr tokens])
  let exprs = []
  while !tokens.first().at(:type).pipe(this:set)
    let [expr new_tokens] = verify_exists!(this:parser(tokens) this)
    exprs:push(expr)
    tokens = new_tokens
  end
  return [{...expr, this:kw => exprs} tokens]
end

fn Case(@parse_map, @kw) end
fn Case:prototype.parse([expr tokens])
  if let [new_expr, new_tokens] = this:parse_map(tokens)
    if this:kw
      return [{...expr, this:kw => new_expr}, new_tokens]
    else
      return [new_expr new_tokens]
    end
  else
    console.log(this:tokens.first(), this:parse_map)
    raise!(Error["Case Parse Failed"])
  end
end

fn Either(@set, @kw) end
fn Either:prototype.parse([expr tokens])
  let op = verify_exists!(this:set(tokens.first().at(:type)), this:set)
  let [new_expr, rest] = [tokens.first(), tokens:skip(1)]
  return [{...expr this:kw => new_expr.at(:value)}, rest]
end

fn Parser(...@instructions) end
fn Parser:prototype.invoke(tokens) = this.parse([nil tokens])

fn AbortIf(@cond_fn) end

fn Parser:prototype.parse(result)
  for instruction of this:instructions
    if instruction.is_a?(AbortIf)
      if instruction:cond_fn(result)
        return
      else
        continue
      end
    end
    result = instruction.parse(result)
  end
  return result
end

fn ParseMap(@entries) end

fn ParseMap:prototype.(Record:keys) =
  this:entries.map(|[pattern _]| pattern).into(Set[])

fn ParseMap:prototype.invoke(tokens, ...args)
  if tokens.empty?()
    return
  else
    for [pattern parser] of this:entries
      if pattern.can_parse?(tokens)
        return parser(tokens, ...args)
      end
    end
  end
end

let algebra_ops = Set[:mod :plus :minus :times :pow :div :lt :gt :lt_eq :gt_eq]

fn parse_dot(tokens, lhs) = Parser[
  Init[{type: :dot, lhs: lhs}]
  Chomp[:dot]
  Then[parse_single_expr :rhs]
](tokens)

fn parse_keyword_lookup(tokens, lhs) = Parser[
  AbortIf[not_adjacent?]    
  Init[{type: :keyword_lookup, lhs: lhs}]
  One[:keyword :property]
  FMap[|{lhs, type, property}| {lhs: lhs, type: type, property: property:slice(1)}]
](tokens)

fn not_adjacent?([_expr tokens])
  let current = tokens.first()
  let previous = tokens:collection.at(tokens:idx - 1)
  if current:line != previous:line
    return true
  else
    let end_of_prev_token = previous:col + previous:value:length
    return (current:col - end_of_prev_token) >= 1
  end
end

fn parse_adjacent_expr(tokens) = Parser[
  AbortIf[not_adjacent?]
  Then[parse_expr]
](tokens)

fn parse_inclusive_range(tokens lhs) = Parser[
  AbortIf[not_adjacent?]
  Init[{type: :inclusive_range, lhs: lhs}]
  Chomp[:dot_dot :eq]
  Optional[SINGLE_EXPR_PARSE_MAP.keys() parse_adjacent_expr :rhs]
](tokens)

fn parse_exclusive_range(tokens lhs) = Parser[
  AbortIf[not_adjacent?]
  Init[{type: :exclusive_range, lhs: lhs}]
  Chomp[:dot_dot]
  Optional[SINGLE_EXPR_PARSE_MAP.keys() parse_adjacent_expr :rhs]
](tokens)

fn parse_fn_call(tokens lhs) = Parser[
  AbortIf[not_adjacent?]
  Init[{type: :fn_call, lhs: lhs}]
  Chomp[:open_p]
  Until[:close_p parse_expr :args]
  Chomp[:close_p]
](tokens)

fn parse_meta_from_entries(tokens lhs) = Parser[
  AbortIf[not_adjacent?]
  Init[{type: :meta_from_entries, lhs: lhs}]
  Chomp[:open_b]
  Until[:close_b parse_record_entry :entries]
  Chomp[:close_b]
](tokens lhs)

fn parse_meta_create(tokens lhs) = Parser[
  AbortIf[not_adjacent?]
  Init[{type: :meta_create, lhs: lhs}]
  Chomp[:open_sq]
  Until[:close_sq parse_expr :entries]
  Chomp[:close_sq]
](tokens lhs)

fn parse_snd_expr_step(tokens, lhs) = ParseMap{
  :open_p => parse_fn_call
  :open_b => parse_meta_from_entries
  :open_sq => parse_meta_create
  :dot => parse_dot
  :keyword => parse_keyword_lookup
  [:dot_dot :eq] => parse_inclusive_range
  :dot_dot => parse_exclusive_range
}(tokens, lhs)

fn parse_snd_expr([lhs tokens])  
  while let [new_lhs rest] = parse_snd_expr_step(tokens, lhs)
    lhs = new_lhs
    tokens = rest
  end
  return [lhs tokens]
end

fn parse_algebra_op(tokens, lhs) = Parser[
  Init[{type: :algebra_op, lhs: lhs}]
  Either[algebra_ops :op]
  Then[parse_1_2_expr :rhs]
](tokens)

fn parse_third_expr_step(tokens, lhs) = ParseMap{
  algebra_ops => parse_algebra_op  
}(tokens, lhs)

fn parse_third_expr([lhs tokens])
   while let [new_lhs rest] = parse_third_expr_step(tokens, lhs)
    lhs = new_lhs
    tokens = rest
  end
  return [lhs tokens]
end

let equality_ops = Set[:double_eq :not_eq]

fn parse_eq_op(tokens, lhs) = Parser[
  Init[{type: :equality_op, lhs: lhs}]
  Either[equality_ops :op]
  Then[parse_1_2_3_expr :rhs]
](tokens)

fn parse_fourth_expr_step(tokens, lhs) = ParseMap{
  equality_ops => parse_eq_op
}(tokens, lhs)

fn parse_fourth_expr([lhs tokens])
   while let [new_lhs rest] = parse_fourth_expr_step(tokens, lhs)
    lhs = new_lhs
    tokens = rest
  end
  return [lhs tokens]
end

fn parse_and(tokens lhs) = Parser[
  Init[{type: :and, lhs: lhs}]
  Chomp[:and]
  Then[parse_1_2_3_4_expr :rhs]
](tokens)

fn parse_or(tokens lhs) = Parser[
  Init[{type: :or, lhs: lhs}]
  Chomp[:or]
  Then[parse_1_2_3_4_expr :rhs]
](tokens)

fn parse_fifth_expr_step(tokens, lhs) = ParseMap{
  :and => parse_and
  :or => parse_or
}(tokens, lhs)

fn parse_fifth_expr([lhs tokens])
   while let [new_lhs rest] = parse_fifth_expr_step(tokens, lhs)
    lhs = new_lhs
    tokens = rest
  end
  return [lhs tokens]
end

let parse_regex = Parser[
  Init[{type: :regex_lit}]
  One[:regex_lit :value]
]

let parse_str = Parser[
  Init[{type: :str}]
  One[:string_lit :value]
]

let valid_ids_in_all_contexts = Set[:id :from]

let parse_id = Parser[
  Init[{type: :id_lookup}]
  Either[Set[...valid_ids_in_all_contexts :import] :name]
]

fn parse_obj(tokens) = Parser[
  Init[{type: :object_literal}]
  Chomp[:open_b]
  Until[:close_b parse_record_entry :entries]
  Chomp[:close_b]
](tokens)

let parse_spread_assign = Parser[
  Init[{type: :spread_assign}]
  Chomp[:dot_dot_dot]
  Either[valid_ids_in_all_contexts :name]
]

let parse_assign_id = Parser[
  Init[{type: :id_assign}]
  Either[valid_ids_in_all_contexts :name]
]

fn parse_assign_array(tokens) = Parser[
  Init[{type: :array_deconstruction}]
  Chomp[:open_sq]
  Until[:close_sq parse_assign_expr :entries]
  Chomp[:close_sq]
](tokens)

let parse_obj_entry_rename = Parser[
  Init[{type: :obj_entry_rename}]
  Either[valid_ids_in_all_contexts :old_name]
  Chomp[:colon]
  Either[valid_ids_in_all_contexts :new_name]
]

let parse_regular_obj_assign_entry = Parser[
  Init[{type: :obj_reg_entry}]
  Either[valid_ids_in_all_contexts :name]
]

fn parse_obj_entry_destructure(tokens) = Parser[
  Init[{type: :obj_assign_expr}]
  Either[valid_ids_in_all_contexts :property]
  Chomp[:colon]
  Then[parse_assign_expr :assign_expr]
](tokens)

let parse_obj_assign_entry = ParseMap{
  [:id :colon :id] => parse_obj_entry_rename
  [:id :colon] => parse_obj_entry_destructure
  :id => parse_regular_obj_assign_entry
  :dot_dot_dot => parse_spread_assign
}

let parse_assign_obj = Parser[
  Init[{type: :object_deconstruction}]
  Chomp[:open_b]
  Until[:close_b parse_obj_assign_entry :entries]
  Chomp[:close_b]
]

let parse_this_assign = Parser[
  Init[{type: :this_assign}]
  Chomp[:at]
  Either[valid_ids_in_all_contexts :name]
]

let parse_this_spread_assign = Parser[
  Init[{type: :this_spread_assign}]
  Chomp[:dot_dot_dot :at]
  One[:id :name]
]

let parse_assign_expr = ParseMap{
  :id => parse_assign_id
  :open_sq => parse_assign_array
  :open_b => parse_assign_obj
  :at => parse_this_assign
  [:dot_dot_dot :at] => parse_this_spread_assign
  :dot_dot_dot => parse_spread_assign
}

fn parse_paren_expr(tokens) = Parser[
  Init[{type: :paren_expr}]
  Chomp[:open_p]
  Then[parse_expr :expr]
  Chomp[:close_p]
](tokens)

fn parse_yield(tokens) = Parser[
  Init[{type: :yield}]
  Chomp[:yield]
  Optional[:times parse_gen_modifier :star?]
  Then[parse_expr :expr]
](tokens)

fn parse_await(tokens) = Parser[
  Init[{type: :await}]
  Chomp[:await]
  Then[parse_expr :expr]
](tokens)

let parse_num = Parser[Init[{type: :num}] One[:num :value]]

fn parse_array(tokens) = Parser[
  Init[{type: :array}]
  Chomp[:open_sq]
  Until[:close_sq parse_expr :elements]
  Chomp[:close_sq]
](tokens)

fn parse_spread(tokens) = Parser[
  Init[{type: :spread}]
  Chomp[:dot_dot_dot]
  Then[parse_expr :expr]
](tokens)

fn parse_not(tokens) = Parser[
  Init[{type: :not}]
  Chomp[:bang]
  Then[parse_expr :expr]
](tokens)

let parse_async_modifier = Parser[
  Init[{}]
  Chomp[:async]
]

let parse_gen_modifier = Parser[
  Init[{}]
  Chomp[:times]
]

fn parse_fn_expr_body(tokens) = Parser[
  Init[{type: :return}]
  Chomp[:eq]
  Then[parse_expr :expr]
  FMap[|node| [node]]
](tokens)

fn parse_args_def(tokens) = Parser[
  Chomp[:open_p]
  Until[:close_p parse_assign_expr]
  Chomp[:close_p]
](tokens)

fn parse_name_expr(tokens)
  if let [expr tokens] = parse_single_expr(tokens)
    let parse_map = ParseMap{
      :dot => parse_dot
      :keyword => parse_keyword_lookup
    }
    while let [new_expr new_tokens] = parse_map(tokens expr)
      expr = new_expr
      tokens = new_tokens
    end
    return [expr tokens]
  end
end

fn parse_fn(tokens) = Parser[
  Init[{type: :fn}]
  Optional[:async parse_async_modifier :is_async?]
  Chomp[:fn]
  Optional[:times parse_gen_modifier :generator?]
  Then[parse_name_expr :name_expr]
  Optional[:open_p parse_args_def :args]
  Case[ParseMap{
    :eq => parse_fn_expr_body,
    _ => block()
  } :body]
](tokens)

fn parse_keyword_record_entry(tokens) = Parser[
  Init[{type: :keyword_record_entry}]
  One[:id :name]
  Chomp[:colon]
  Then[parse_expr :expr]
](tokens)

fn parse_regular_record_entry(tokens) = Parser[
  Init[{type: :regular_record_entry}]
  Then[parse_expr :key_expr]
  Chomp[:arrow]
  Then[parse_expr :value_expr]
](tokens)

fn parse_record_entry(tokens) = ParseMap{
  :dot_dot_dot => parse_spread
  [:id :colon] => parse_keyword_record_entry
  [:id :arrow] => parse_regular_record_entry
  :fn => parse_fn
  [:async :fn] => parse_fn
  _ => parse_regular_record_entry
}(tokens)

fn parse_prefix_inclusive_range(tokens) = Parser[
  Init[{type: :prefix_inclusive_range}]
  Chomp[:dot_dot :eq]
  Then[parse_expr :expr]
](tokens)

fn parse_prefix_exclusive_range(tokens) = Parser[
  Init[{type: :prefix_exclusive_range}]
  Chomp[:dot_dot]
  Then[parse_expr :expr]
](tokens)

fn parse_keyword(tokens) = Parser[
  Init[{type: :keyword}]
  One[:keyword :value]
  FMap[|{type, value}| {type: type, value: value:slice(1)}]
](tokens)

fn parse_anon_fn(tokens) = Parser[
  Init[{type: :anon_fn}]
  Chomp[:pipe_bar]
  Until[:pipe_bar parse_assign_expr :args]
  Chomp[:pipe_bar]
  Then[parse_expr :return_expr]
](tokens)

fn parse_reassign(tokens) = Parser[
  Init[{type: :reassign}]
  One[:id :name]
  Chomp[:eq]
  Then[parse_expr :expr]
](tokens)

let parse_unapplied_algebra_op = Parser[
  Init[{type: :unapplied_algebra_op}]
  Either[algebra_ops :op]
]

let parse_unapplied_equality_op = Parser[
  Init[{type: :unapplied_equality_op}]
  Either[equality_ops :op]
]

let SINGLE_EXPR_PARSE_MAP = ParseMap{
  :string_lit => parse_str
  :regex_lit => parse_regex
  :keyword => parse_keyword
  :open_p => parse_paren_expr
  :yield => parse_yield
  :await => parse_await
  :num => parse_num
  :open_sq => parse_array
  :dot_dot_dot => parse_spread
  :bang => parse_not
  :open_b => parse_obj
  :pipe_bar => parse_anon_fn
  [:id :eq] => parse_reassign
  [:dot_dot :eq] => parse_prefix_inclusive_range
  :dot_dot => parse_prefix_exclusive_range
  Set[...valid_ids_in_all_contexts :import] => parse_id
  [:async :fn] => parse_fn
  :fn => parse_fn
  equality_ops => parse_unapplied_equality_op
  algebra_ops => parse_unapplied_algebra_op
}

fn parse_single_expr(tokens) = SINGLE_EXPR_PARSE_MAP(tokens)

fn parse_expr(tokens) = parse_fifth_expr(parse_fourth_expr(parse_third_expr(parse_snd_expr(parse_single_expr(tokens)))))

fn parse_1_2_expr(tokens) = parse_snd_expr(parse_single_expr(tokens))

fn parse_1_2_3_expr(tokens) = parse_third_expr(parse_snd_expr(parse_single_expr(tokens)))

fn parse_1_2_3_4_expr(tokens) = parse_fourth_expr(parse_third_expr(parse_snd_expr(parse_single_expr(tokens))))

fn parse_else_branch(tokens) = Parser[
  Init[{type: :else}]  
  Chomp[:else]
  UntilEither[Set[:else :end] parse_statement :body]
](tokens)

fn parse_else_if_branch(tokens) = Parser[
  Init[{type: :else_if}]  
  Chomp[:else :if]
  Then[parse_expr :expr]
  UntilEither[Set[:else :end] parse_statement :pass]
  Optional[:else parse_if_branch :fail]
](tokens)

let parse_if_branch = ParseMap{
  [:else :if] => parse_else_if_branch
  :else => parse_else_branch
}

fn parse_if(tokens) = Parser[
  Init[{type: :if}]
  Chomp[:if]
  Then[parse_expr :expr]
  UntilEither[Set[:else :end] parse_statement :pass]
  Optional[:else parse_if_branch :fail]
  Chomp[:end]
](tokens)

let parse_let = Parser[
  Init[{type: :let}]
  Chomp[:let]
  Then[parse_assign_expr :assign_expr]
  Chomp[:eq]
  Then[parse_expr :rhs]
]

fn parse_if_let(tokens) = Parser[
  Init[{type: :if_let}]
  Chomp[:if :let]
  Then[parse_assign_expr :assign_expr]
  Chomp[:eq]
  Then[parse_expr :expr]
  UntilEither[Set[:else :end] parse_statement :pass]
  Optional[:else parse_else_branch :fail]
  Chomp[:end]
](tokens)

let parse_protocol_methods = Parser[
  Init[{type: :protocol_method}]  
  Chomp[:open_b]
  Until[:close_b parse_id :names]
  Chomp[:close_b]
]

let parse_protocol = Parser[
  Init[{type: :protocol_def}]
  Chomp[:protocol]
  One[:id :name]
  Optional[:open_b parse_protocol_methods :methods]
]

let parse_return = Parser[
  Init[{type: :return}]
  Chomp[:return]
  Optional[SINGLE_EXPR_PARSE_MAP.keys() parse_expr :expr]
]

let parse_await_modifier = Parser[
  Init[true]
  Chomp[:await]
]

fn parse_for_loop(tokens) = Parser[
  Init[{type: :for_loop}]
  Chomp[:for]
  Optional[:await parse_await_modifier :is_await?]
  Then[parse_assign_expr :assign_expr]
  Chomp[:of]
  Then[parse_expr :iterable_expr]
  block(:body)
](tokens)

fn parse_loop(tokens) = Parser[
  Init[{type: :loop}]
  Chomp[:loop]
  block(:body)
](tokens)

fn parse_while_loop(tokens) = Parser[
  Init[{type: :while_loop}]
  Chomp[:while]
  Then[parse_expr :test_expr]
  block(:body)
](tokens)

fn parse_while_let_loop(tokens) = Parser[
  Init[{type: :while_let_loop}]
  Chomp[:while :let]
  Then[parse_assign_expr :assign_expr]
  Chomp[:eq]
  Then[parse_expr :test_expr]
  block(:body)
](tokens)

fn parse_continue(tokens) = Parser[
  Init[{type: :continue}]
  Chomp[:continue]
](tokens)

fn parse_break(tokens) = Parser[
  Init[{type: :break}]
  Chomp[:break]
](tokens)

fn parse_catch(tokens) = Parser[
  Init[{type: :catch}]
  Chomp[:catch]
  One[:id :name]
  block(:body)
](tokens)

fn parse_finally(tokens) = Parser[
  Init[{type: :finally}]
  Chomp[:finally]
  block(:body)
](tokens)

fn parse_try(tokens) = Parser[
  Init[{type: :try}]
  Chomp[:try]
  block(:body)
  Optional[:catch parse_catch :catch]
  Optional[:finally parse_finally :finally]
](tokens)

fn parse_import(tokens) = Parser[
  Init[{type: :import}]
  Chomp[:import]
  Then[parse_assign_expr :assign_expr]
  Chomp[:from]
  Then[parse_str :path]
](tokens)

fn parse_export(tokens) = Parser[
  Init[{type: :export}]
  Chomp[:export]
  Then[parse_statement :statement]
](tokens)

fn parse_export_default(tokens) = Parser[
  Init[{type: :export_default}]
  Chomp[:export :default]
  Then[parse_expr :expr]
](tokens)

let parse_direct_import = Parser[
  Init[{type: :direct_import}]
  Chomp[:import]
  One[:string_lit :path]
]

fn parse_statement(tokens) = ParseMap{
  :let => parse_let
  :for => parse_for_loop
  :try => parse_try
  :protocol => parse_protocol
  :return => parse_return
  :continue => parse_continue
  :break => parse_break
  :loop => parse_loop
  [:import :string_lit] => parse_direct_import
  :import => parse_import
  [:export :default] => parse_export_default
  :export => parse_export
  [:while :let] => parse_while_let_loop
  :while => parse_while_loop
  [:if :let] => parse_if_let
  :if => parse_if
  _ => parse_expr
}(tokens)

fn block(name) = Parser[
  Until[:end parse_statement name]
  Chomp[:end]
]

fn parse_tokens(tokens)
  let ast = []
  while let [statement_or_expr, rest] = parse_statement(tokens)
    ast:push(statement_or_expr)
    tokens = rest
  end
  return ast
end

# END OF PARSING

# START OF EVAL

fn resolve_name(name)
  if name
    return name
      .:replaceAll("?", "__q")
      .:replaceAll("!", "__b")
      .:replaceAll(">", "_lt_")
      .:replaceAll("-", "_")
  else
    return name
  end
end

fn eval_if_branch(branch)
  if branch.nil?()
    return ""
  else if branch.:type == :else
    return str(" else {\n" eval_ast(branch.:body or []) "\n}")
  else if branch.:type == :else_if
    return str(
      " else if (" eval_expr(branch.at(:expr)) ") {\n"
        eval_ast(branch.at(:pass) or [])
      "\n}" eval_if_branch(branch.at(:fail))
    )
  else
    raise!(Error["Expected else if"])
  end
end

fn eval_if({expr, pass, fail}) = str(
  "if (" eval_expr(expr) "[Meta.as_bool]()) {\n"
    eval_ast(pass) "\n"
  "}" eval_if_branch(fail)
)

fn eval_str({value})
  value = value.:slice(1, -1)
  if value.:includes("\n")
    return str("`" value "`")
  else
    return str("\"" value "\"")
  end
end

fn eval_fn_call({lhs args}) = 
  str(eval_expr(lhs) "[invoke](" args.map(eval_expr).join(", ") ")")

fn eval_id_assign_name({name}) = resolve_name(name)

fn eval_spread_assign({name}) = str("..." resolve_name(name))

fn eval_array_deconstruction_entry(node) = node.at(:type).pipe(Map{
  :id_assign => eval_id_assign_name
  :spread_assign => eval_spread_assign
  :array_deconstruction => eval_array_deconstruction_names
  :object_deconstruction => eval_object_deconstruction_names
})(node)

fn eval_array_deconstruction_names({entries}) =
  str("[" entries.map(eval_array_deconstruction_entry).join(", ") "]")

fn eval_obj_reg_entry({name}) = str("'" name "': " resolve_name(name))

fn eval_obj_entry_rename({old_name, new_name}) =
  str("'" old_name "': " resolve_name(new_name))

fn eval_obj_assign_expr({property, assign_expr}) =
  str("'" property "': " eval_assign_expr(assign_expr))

fn eval_obj_deconstruction_entry(node) = node.at(:type).pipe(Map{
  :obj_reg_entry => eval_obj_reg_entry
  :obj_assign_expr => eval_obj_assign_expr
  :obj_entry_rename => eval_obj_entry_rename
  :spread_assign => eval_spread_assign
  :object_deconstruction => eval_object_deconstruction_names
})(node)

fn eval_object_deconstruction_names({entries}) =
  str("{" entries.map(eval_obj_deconstruction_entry).join(", ") "}")

fn eval_this_assign({name}) = resolve_name(name)

fn eval_this_spread_assign({name}) = str("..." resolve_name(name))

fn eval_assign_all_as({name}) = str("* as " name)

fn eval_assign_expr(node) = node.at(:type).pipe(Map{
  :id_assign => eval_id_assign_name
  :spread_assign => eval_spread_assign
  :array_deconstruction => eval_array_deconstruction_names
  :object_deconstruction => eval_object_deconstruction_names
  :this_assign => eval_this_assign
  :this_spread_assign => eval_spread_assign
})(node)

fn eval_while_let_loop({test_expr, assign_expr, body}) = str(
  "var __coil_while_let_temp = " eval_expr(test_expr) " ?? nil;\n"
  "while (__coil_while_let_temp[Meta.as_bool]()) {\n"
    "let " eval_assign_expr(assign_expr) " = __coil_while_let_temp;\n"
    eval_ast(body) "\n"
    "__coil_while_let_temp = " eval_expr(test_expr) " ?? nil;\n"
  "}")

fn eval_if_let({expr, assign_expr, pass, fail}) = str(
  "var __coil_if_let_temp = " eval_expr(expr) " ?? nil;\n"
  "if (__coil_if_let_temp[Meta.as_bool]()) {\n"
    "let " eval_assign_expr(assign_expr) " = __coil_if_let_temp;\n"
    eval_ast(pass) "\n"
  "}" eval_if_branch(fail)
)

fn eval_spread({expr}) = str("..." eval_expr(expr))

fn eval_let({assign_expr, rhs}) =
  str("let " eval_assign_expr(assign_expr) " = " eval_expr(rhs))

fn eval_array({elements}) = str("[" elements.map(eval_expr).join(", ") "]")

fn eval_this_assignments(args) = args
  .filter(:type Set[:this_assign :this_spread_assign])
  .map(|{name}| str("this['" name "'] = " resolve_name(name) ";\n"))
  .into("")

fn eval_name_expr(node) = node.at(:type).pipe(Map{
  fn :dot({lhs rhs}) = str(eval_name_expr(lhs) "[" eval_name_expr(rhs) "]")
  fn :keyword_lookup({lhs, property}) = str(eval_name_expr(lhs) "['" property  "']")
} |eval_fn| eval_fn or eval_expr)(node)

fn entries_arg_names({entries}) =
  entries:flatMap(arg_names)

fn arg_names(node) = node.at(:type).pipe(Map{
  :array_deconstruction => entries_arg_names
  :object_deconstruction => entries_arg_names
  fn :id_assign({name}) = [name]
  fn :obj_reg_entry({name}) = [name]
  fn :obj_entry_rename({new_name}) = [new_name]
  fn :spread_assign({name}) = [name]
  fn :obj_str_rename_entry({new_name}) = [new_name]
  fn :this_assign({name}) = [name]
  fn :this_spread_assign({name}) = [name]
})(node)

fn eval_nil_destructure_args(args)
  if args
    return args:flatMap(arg_names)
      .map(|name| str(resolve_name(name) " ??= nil;"))
      .join("\n")
  else
    return ""
  end
end

fn eval_fn_expr({is_async? generator? args body}) = str(
  (is_async? and "async ")
  "function "
    (generator? and "*")
    "(" (args or []).map(eval_assign_expr).join(", ") ") {\n"
    eval_this_assignments(args or [])
    eval_nil_destructure_args(args or [])
    eval_ast(body)
  "}")

fn eval_fn(node) = str(
  (node:name_expr:type == :id_lookup and "let ") or ""
  eval_name_expr(node:name_expr) " = "
  eval_fn_expr(node)
)

fn eval_obj_fn({name generator? is_async? args body}) =
  str((is_async? and "async ")
      (generator? and "*")
      "['" name "'](" args.map(eval_assign_expr).join(", ") ") {\n"
      eval_ast(body) "\n}")

fn eval_id_lookup({name}) = resolve_name(name)

fn eval_num({value}) = str("(" value ")")

fn eval_double_equals({lhs, rhs}) =
  str(eval_expr(lhs) "[Equal['==']](" eval_expr(rhs) ")")

fn eval_not_equals({lhs, rhs}) = str(eval_expr(lhs) "[Equal['!=']](" eval_expr(rhs) ")")

fn eval_not({expr}) = str(eval_expr(expr) "[Bool.negate]()")

fn eval_meta_from_entries({lhs entries}) = 
  str(eval_expr(lhs) "[Meta.from_entries](["
    entries.map(eval_record_entry).join(", ") "])")

fn eval_meta_create({lhs, entries}) =
  str(eval_expr(lhs) "[Meta.create]([" entries.map(eval_expr).join(", ") "])")

fn eval_await({expr}) = str("await " eval_expr(expr))

fn eval_yield({star? expr}) = str("yield" (star? and "*") " " eval_expr(expr))

fn eval_paren_expr({expr}) = str("(" eval_expr(expr) ")")

fn eval_keyword({value}) = str("Keyword.for(\"" value  "\")")

fn eval_regular_record_entry({key_expr value_expr}) =
  str("[" eval_expr(key_expr) ", " eval_expr(value_expr) "]")

fn eval_keyword_record_entry({name expr}) =
  str("[" eval_keyword({value: name}) ", " eval_expr(expr) "]")

fn eval_fn_record_entry(fn_node) =
  str("[" eval_expr(fn_node:name_expr) ", " eval_fn_expr(fn_node) "]")

fn eval_record_entry(node) = node.at(:type).pipe(Map{
  :regular_record_entry => eval_regular_record_entry
  :keyword_record_entry => eval_keyword_record_entry
  :spread => eval_spread
  :fn => eval_fn_record_entry
})(node)

fn eval_inclusive_range({lhs, rhs})
  if rhs
    return str("new InclusiveRange(" eval_expr(lhs) ", " eval_expr(rhs) ")")
  else
    return str("new InclusiveRangeNoMaximum(" eval_expr(lhs) ")")
  end
end

fn eval_exclusive_range({lhs, rhs})
  if rhs
    return str("new ExclusiveRange(" eval_expr(lhs) ", " eval_expr(rhs) ")")
  else
    return str("new ExclusiveRangeNoMaximum(" eval_expr(lhs) ")")
  end
end

fn eval_regex_lit({value}) = value

fn eval_prefix_exclusive_range({expr}) = str("new ExclusiveRangeNoMinimum(" eval_expr(expr) ")") 

fn eval_prefix_inclusive_range({expr}) = str("new InclusiveRangeNoMinimum(" eval_expr(expr) ")")

fn eval_dot({lhs, rhs}) = str("dot(" eval_expr(lhs) ", " eval_expr(rhs) ")")

fn eval_keyword_lookup({lhs property}) =
  str("dot(" eval_expr(lhs) ", '" property "')")

fn eval_object_literal({entries}) = str(
  "ObjectLiteral[Meta.from_entries](["
    entries.map(eval_record_entry).join(", ")
  "])"
)

fn eval_anon_fn({args, return_expr}) = str(
  "(" args.map(eval_assign_expr).join(", ") ") => {\n"
    eval_nil_destructure_args(args)
    "return " eval_expr(return_expr) ";"
  "}"
)

fn eval_algebra_op({lhs, op, rhs}) = str(
  eval_expr(lhs) "[Algebra[\"" op "\"]](" eval_expr(rhs) ")"
)

fn eval_equality_op({lhs, op, rhs}) = str(
  eval_expr(lhs) "[Meta[\"" op "\"]](" eval_expr(rhs)")"
)

fn eval_and({lhs, rhs}) = str(
  "(__coil_temp = {left: " eval_expr(lhs) "}"
  ", __coil_temp.left[Meta.as_bool]() === false ? __coil_temp.left : (__coil_temp.right = " eval_expr(rhs) ", __coil_temp.right[Meta.as_bool]() === true) ? __coil_temp.right : __coil_temp.left)"
)

fn eval_or({lhs, rhs}) = str(
  "(__coil_temp = {left: " eval_expr(lhs) "}"
  ", __coil_temp.left[Meta.as_bool]() ? __coil_temp.left : " eval_expr(rhs) ")"
)

fn eval_reassign({name, expr}) = str(resolve_name(name) " = " eval_expr(expr))

fn eval_unapplied_algebra_op({op}) = str("Algebra['" op "']")

fn eval_unapplied_equality_op({op}) = str("Meta['" op "']")

fn eval_expr(node) = node.at(:type).pipe(Map{
  :algebra_op => eval_algebra_op
  :unapplied_algebra_op => eval_unapplied_algebra_op
  :unapplied_equality_op => eval_unapplied_equality_op
  :equality_op => eval_equality_op
  :and => eval_and
  :or => eval_or
  :str => eval_str
  :dot => eval_dot
  :reassign => eval_reassign
  :keyword_lookup => eval_keyword_lookup
  :object_literal => eval_object_literal
  :regex_lit => eval_regex_lit
  :keyword => eval_keyword
  :prefix_exclusive_range => eval_prefix_exclusive_range
  :prefix_inclusive_range => eval_prefix_inclusive_range
  :id_lookup => eval_id_lookup
  :fn_call => eval_fn_call
  :num => eval_num
  :array => eval_array
  :double_equals => eval_double_equals
  :not_equals => eval_not_equals
  :not => eval_not
  :fn => eval_fn
  :meta_from_entries => eval_meta_from_entries
  :meta_create => eval_meta_create
  :spread => eval_spread
  :await => eval_await
  :yield => eval_yield
  :paren_expr => eval_paren_expr
  :inclusive_range => eval_inclusive_range
  :exclusive_range => eval_exclusive_range
  :anon_fn => eval_anon_fn
})(node)

fn eval_return({expr})
  if expr
    return str("return " eval_expr(expr))
  else
    return "return"
  end
end

fn eval_protocol({name, methods})
  if methods
    return str(
      "const " name " = Object.freeze({"
        methods.names
          .map(|method| str("\"" method:name "\": Symbol(\"" name ":" method:name "\")"))
          .join(",\n")
      "})"
    )
  else
    return str("const " resolve_name(name) " = Symbol(\"" name "\")")
  end
end

fn eval_for_loop({is_await? assign_expr iterable_expr body}) = 
  str("for "
      (is_await? and "await ")
      " (let " eval_assign_expr(assign_expr) " of "
      eval_expr(iterable_expr) ") {\n"
        eval_ast(body) "\n"
      "}")

fn eval_id_assign({name, expr}) = str(resolve_name(name) " = " eval_expr(expr))

fn eval_while_loop({test_expr, body}) =
  str("while (" eval_expr(test_expr) "[Meta.as_bool]()) {\n" eval_ast(body) "\n}")

fn eval_loop({body}) = str("while (true) {\n" eval_ast(body) "\n}")

fn eval_continue() = "continue"

fn eval_break() = "break"

fn eval_try(node)
  let body_js = node.at(:body).pipe(eval_ast)
  let catch_js = ""
  let finally_js = ""
  if node.has?(:catch)
    let {name, body} = node.at(:catch)
    catch_js = str(" catch (" name ") {\n" eval_ast(body) "\n}")
  end
  if node.has?(:finally)
    let {body} = node.at(:finally)
    finally_js = str(" finally {\n" eval_ast(body) "\n}")
  end
  return str("try {\n" body_js "\n" "}" catch_js finally_js)
end

fn get_deconstructed_obj_entry_name(node) =
  Map{:obj_reg_entry => :name
      :obj_entry_rename => :old_name}
    .at(node.at(:type))
    .pipe(node)

fn get_deconstructed_array_entry_name(node) =
  Map{:id_assign => :name}.at(node.at(:type)).pipe(node)

fn eval_import_deconstruction_entry(node) = node.pipe(:type Map{
  fn :obj_reg_entry({name}) = resolve_name(name)
  fn :obj_entry_rename({old_name, new_name}) =
    str(resolve_name(old_name) " as " resolve_name(new_name))
})(node)

fn eval_import_deconstruction_expr({entries}) =
  str("{" entries.map(eval_import_deconstruction_entry).join(", ") "}")

fn eval_import_assign_exprs(node) = node.pipe(:type Map{
  :id_assign => eval_id_assign_name
  :object_deconstruction => eval_import_deconstruction_expr
  :assign_all_as => eval_assign_all_as
})(node)

fn eval_import({assign_expr, path}) =
  str("import "
    eval_import_assign_exprs(assign_expr)
    " from \"" path:value:slice(1, -1) "\"")

fn eval_export({statement}) = str("export " eval_statement(statement))

fn eval_export_default({expr}) = str("export default " eval_expr(expr))

fn eval_direct_import({path}) = str("import " path)

fn eval_statement(node)
  let eval_fn = node.at(:type).pipe(Map{
    :if => eval_if
    :direct_import => eval_direct_import
    :import => eval_import
    :export => eval_export
    :export_default => eval_export_default
    :let => eval_let
    :if_let => eval_if_let
    :return => eval_return
    :protocol_def => eval_protocol
    :for_loop => eval_for_loop
    :id_assign => eval_id_assign
    :while_loop => eval_while_loop
    :loop => eval_loop
    :while_let_loop => eval_while_let_loop
    :continue => eval_continue
    :break => eval_break
    :try => eval_try
  })

  if eval_fn
    return eval_fn(node) + ";"
  else
    return eval_expr(node)
  end
end

export fn eval_ast(ast) =
  str("let __coil_temp;\n" ast.map(eval_statement).join("\n"))

export fn lex(string) = lexer(string)

fn coll_view(tokens) = CollectionView[tokens, 0]

export fn lex_and_parse(string) = string.pipe(lexer coll_view parse_tokens)

export fn compile(string) = string.pipe(lexer coll_view parse_tokens eval_ast)

let [src_file_name, out_name, ...args] = Deno:args
let src = Deno:readTextFileSync(src_file_name)

let std_prefix = "."
if let arg = args.find(_.has?("--std-prefix"))
  std_prefix = arg:split("--std-prefix=").last()
end

let imports = str("
\"use strict\";
import { ObjectLiteral, Nil, nil, Keyword, dot, raise__b } from '" std_prefix "/src/std/globals.js'
import Meta, {
  nil__q, is_a__q, create, from_entries, as_num, exists__q, as_bool, log, invoke, pipe
} from '" std_prefix "/src/std/meta.js';
import Iter, {
  take, until, skip, find, zip, reduce, map, flat_map, each,
  filter, reject, all__q, any__q, split, compact, join, into, compose
} from '" std_prefix "/src/std/iter/index.js';
import Algebra from '" std_prefix "/src/std/algebra.js';
import Bool, { negate } from '" std_prefix "/src/std/bool.js';
import Collection, { at, len, empty__q, has__q } from '" std_prefix "/src/std/collection.js';
import OrderedSequence, { first, last } from '" std_prefix "/src/std/ordered_sequence.js';
import {
  inc, InclusiveRange, ExclusiveRange, InclusiveRangeNoMaximum,
  InclusiveRangeNoMinimum, ExclusiveRangeNoMaximum, ExclusiveRangeNoMinimum
} from '" std_prefix "/src/std/range.js';
import Record, { keys, values } from '" std_prefix "/src/std/record.js';
import Underscore, { _ } from '" std_prefix "/src/std/underscore.js';
import CondMap from '" std_prefix "/src/std/cond_map.js'
")
Deno:writeTextFile(out_name, imports + compile(src) + "\n")
